Thinking1 机器学习中的监督学习、非监督学习、强化学习有何区别
Answer1 监督学习：有标签	非监督学习：没有标签     强化学习：有奖励信号

Thinking2 什么是策略网络，价值网络，有何区别
Answer2 策略网络：对于给定的输入，通过学习给出一个确定输出的网络：（动作1，状态1），（动作2，状态2）
               价值网络：通过计算目前状态s的累积分数的期望，给游戏中的状态赋予一个分数（数值），每个状态都经历了整个数值网络
               区别：策略网络的输出是一个落子的概率分布；价值网络的输出是一个可能获胜的数值，即“价值”；
	         策略网络能学到一些随机策略，而价值网络通常是学不到的

Thinking3 请简述MCTS（蒙特卡洛树搜索）的原理，4个步骤Select, Expansion，Simluation，Backpropagation是如何操作的
Answer3 原理：每个节点代表一个局面，A/B代表被访问B次，黑棋赢了A次 
               Selection：从根节点状态出发，迭代地使用UCB1算法选择最优策略，直到碰到一个叶子节点 
               Expansion：对叶子节点进行扩展。选择其一个从未访问过的子节点加入当前的搜索树
               Simluation：从扩展的新节点出发，进行模拟，直到博弈结束
               Backpropagation：更新博弈树中所有节点的状态。进入下一轮的选择和模拟

Thinking4 假设你是抖音的技术负责人，强化学习在信息流推荐中会有怎样的作用，如果要进行使用强化学习，都有哪些要素需要考虑
Answer4 强化学习在信息流推荐中会是推荐结果更加智能化，通过持续机器学习和模型优化建立决策引擎，
               对海量用户行为以及item特征进行实时分析，帮用户快速发现喜欢的item（商品、视频等）

Thinking5 在自动驾驶中，如何使用强化学习进行训练，请说明简要的思路
Answer5 自动驾驶主要是考虑个体（Agent）与环境（Environment）的交互问题，目标是找到一个最优策略，使Agent获得尽可能多的来自环境的奖励
               汽车是Agent，汽车的位置是状态，对汽车的操作是动作，怎样操作汽车是策略，驾驶的完成情况是奖励
               很多情况下，Agent无法获取全部的环境信息，而是通过观察(Observation)来表示环境（environment），也就是得到的是自身周围的信息

 
               

